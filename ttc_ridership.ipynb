{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing & Cleaning - TTC Ridership\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report outlines the steps taken to clean the following data sets:\n",
    "\n",
    "- Open Toronto Data: TTC Ridership data\n",
    "\n",
    "We will perform the following steps to process & clean the data into its final form for analysis: \n",
    "\n",
    "1. General data review\n",
    "2. Data compilation/consolidation ('raw' --> 'processed')\n",
    "3. Data cleaning ('processed' --> 'clean_final')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import src.paths as pt\n",
    "import src.mappings as maps\n",
    "import imp \n",
    "imp.reload(pt)\n",
    "imp.reload(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General Data Review\n",
    "\n",
    "The dataset, reported by the TTC, tracks the passengers on the transit system and is shared every quarter. \n",
    "\n",
    "The extracted data includes the following features for each year + month from 2007 onwards (see README for data extraction process/parameters): \n",
    "\n",
    "- Average Weekday Ridership  \n",
    "- Monthy Ridership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Compilation/Consolidation \n",
    "\n",
    "The ridership data is kept in melted format. For analysis purposes, the data is pivoted/unmelted within the 'data_compiling.py' script and is stored in the 'data/processed/ridership' folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning\n",
    "\n",
    "Below are the general steps taken to clean the data: \n",
    "\n",
    "- Inspection: types, summaries, counts, outliers\n",
    "- Cleaning: \n",
    "    - Remove irrelevant data if necessary  \n",
    "    - Data types\n",
    "    - Check for duplicates\n",
    "    - Syntax, typos (re-mapping)\n",
    "    - Check for missing values: \n",
    "        - Remove records if random or rare occurences, \n",
    "        - Impute, \n",
    "        - Flag \"missing\"\n",
    "    - Scaling/Transformations/Normalization if necessary \n",
    "    - Review outliers and determine keep/remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}